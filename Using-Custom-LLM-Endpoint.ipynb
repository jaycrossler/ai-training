{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jaycrossler/ai-training/blob/main/Using-Custom-LLM-Endpoint.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d062295-3f3b-4298-b6e2-c1c17d46e9ea",
      "metadata": {
        "id": "9d062295-3f3b-4298-b6e2-c1c17d46e9ea"
      },
      "source": [
        "# Using Custom LLM Endpoints\n",
        "## This must run within your company's firewall\n",
        "\n",
        "This notebook demonstates how you can use LLMs that are hosted within your own organization/enterprise. In this notebook, we will be using Custom company hosted LLMs to demonstrate this. You will need to enter in a **COMPANY_API_KEY** into colab (the key icon on the left) as well as the company domain to point to.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "09d55f49-018a-46c4-9430-73bb6614ff25",
      "metadata": {
        "id": "09d55f49-018a-46c4-9430-73bb6614ff25"
      },
      "outputs": [],
      "source": [
        "%%capture --no-stderr\n",
        "# install the required dependencies\n",
        "%pip install -U langchain-openai langgraph langchain_openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "1eb4c74e-3c20-4d0b-b1c8-04cf90d0db98",
      "metadata": {
        "id": "1eb4c74e-3c20-4d0b-b1c8-04cf90d0db98",
        "outputId": "f645e743-211e-4c7e-fd26-1925d4050761",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "COMPANY_API_KEY:It's a secret...\n",
            "Domain to point API calls to (e.g. 'someplace.org'):someplace.org\n"
          ]
        }
      ],
      "source": [
        "# If not using google colab, comment this out and enter your key below\n",
        "from google.colab import userdata\n",
        "\n",
        "CUSTOM_API_KEY = input(\"COMPANY_API_KEY:\")\n",
        "CUSTOM_DOMAIN = input(\"Domain to point API calls to (e.g. 'someplace.org'):\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "fc5bb440-e68d-473a-a8c4-80eae42fc233",
      "metadata": {
        "id": "fc5bb440-e68d-473a-a8c4-80eae42fc233"
      },
      "outputs": [],
      "source": [
        "from typing import Optional, Literal\n",
        "from typing_extensions import TypedDict\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langchain_openai import ChatOpenAI\n",
        "import random\n",
        "\n",
        "# Input Object\n",
        "class InputState(TypedDict):\n",
        "    query: str\n",
        "\n",
        "# Output Object\n",
        "class OutputState(InputState):\n",
        "    dice_roll: int\n",
        "    user_guess: int\n",
        "    response: str\n",
        "\n",
        "# Create a generic client\n",
        "def create_generic_client(\n",
        "    base_url: str,\n",
        "    model: str,\n",
        "    api_key: str,\n",
        "    temperature=0.8,\n",
        "):\n",
        "    return ChatOpenAI(\n",
        "        temperature=temperature,\n",
        "        api_key=api_key,\n",
        "        base_url=base_url,\n",
        "        model=model,\n",
        "        top_p=0.3,\n",
        "    )\n",
        "\n",
        "# Custom hosted LLM Endpoints\n",
        "# Mixtral 22B parameter\n",
        "CUSTOM_MIXTRAL_8x22B_URL = \"https://mixtral-8x22b.k8s.aip.{}/v1\".format(CUSTOM_DOMAIN)\n",
        "CUSTOM_MIXTRAL_8x22B_MODEL = \"mistralai/Mixtral-8x22B-Instruct-v0.1\"\n",
        "\n",
        "# Llama 70B parameter\n",
        "CUSTOM_LLAMA_11B_URL = \"https://llama32-11b.k8s.aip.{}/v1\".format(CUSTOM_DOMAIN)\n",
        "CUSTOM_LLAMA_11B_MODEL = \"meta/llama-3.2-11b-vision-instruct\"\n",
        "\n",
        "# Feel free to choose one of the two LLM endpoints defined above\n",
        "# Here, we are using the Mixtral endpoint/model\n",
        "client = create_generic_client(base_url=CUSTOM_MIXTRAL_8x22B_URL,\n",
        "                               model=CUSTOM_MIXTRAL_8x22B_MODEL,\n",
        "                               api_key=CUSTOM_API_KEY)\n",
        "\n",
        "async def user_guess(state: InputState) -> OutputState:\n",
        "    messages = [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"You are a helpful assistant. Extract the users guess for the dice roll and return the guess as a numerical value. Do not provide any explanation, just the number that the user guessed\",\n",
        "        ),\n",
        "        (\"human\", state[\"query\"]),\n",
        "    ]\n",
        "\n",
        "    guess = client.invoke(messages).content\n",
        "    return OutputState(user_guess=int(guess))\n",
        "\n",
        "\n",
        "async def roll_dice(state: OutputState) -> OutputState:\n",
        "    return OutputState(dice_roll=random.randint(1, 6))\n",
        "\n",
        "async def success_message(state: OutputState) -> OutputState:\n",
        "    return OutputState(response=\"Congratulations!!!! You hit the Jackpot\")\n",
        "\n",
        "async def passifying_message(state: OutputState) -> OutputState:\n",
        "    response = client.invoke(\"In 2 to 3 sentences, tell a shirt positive, uplifting story to cheer someone up when they are down on their luck.\")\n",
        "    return OutputState(response=response.content)\n",
        "\n",
        "\n",
        "async def router(state: OutputState) -> Literal[\"success\", \"failure\"]:\n",
        "    return \"success\" if state[\"dice_roll\"]==state[\"user_guess\"] else \"failure\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "540369cf-91c7-4c43-8e1e-9f25e9e34d42",
      "metadata": {
        "id": "540369cf-91c7-4c43-8e1e-9f25e9e34d42",
        "outputId": "5dbc689b-076a-4f6d-c588-1c16a1d676bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-056fdb2cbe29>:2: LangGraphDeprecationWarning: Initializing StateGraph without state_schema is deprecated. Please pass in an explicit state_schema instead of just an input and output schema.\n",
            "  workflow_builder = StateGraph(input=InputState, output=OutputState)\n"
          ]
        }
      ],
      "source": [
        "# Set up a workflow for multiple AI states (in LangGraph format)\n",
        "workflow_builder = StateGraph(input=InputState, output=OutputState)\n",
        "workflow_builder.add_node(\"guess\", user_guess)\n",
        "workflow_builder.add_node(\"roll_the_dice\", roll_dice)\n",
        "workflow_builder.add_node(\"success\", success_message)\n",
        "workflow_builder.add_node(\"failure\", passifying_message)\n",
        "\n",
        "workflow_builder.add_edge(START, \"guess\")\n",
        "workflow_builder.add_edge(\"guess\", \"roll_the_dice\")\n",
        "workflow_builder.add_conditional_edges(\"roll_the_dice\", router)\n",
        "workflow_builder.add_edge(\"success\", END)\n",
        "workflow_builder.add_edge(\"failure\", END)\n",
        "\n",
        "workflow = workflow_builder.compile()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "255baca9-bf8c-4175-8db4-e639c94c49cc",
      "metadata": {
        "id": "255baca9-bf8c-4175-8db4-e639c94c49cc",
        "outputId": "d72ba78a-2eb2-4996-b29e-cbe849d4f25b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Visulaizing the Workflow...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Visualize the LangGraph workflow as a graph\n",
        "from IPython.display import Image, display\n",
        "from langchain_core.runnables.graph import MermaidDrawMethod\n",
        "\n",
        "print(\"Visulaizing the Workflow...\")\n",
        "\n",
        "display(\n",
        "    Image(\n",
        "        workflow.get_graph().draw_mermaid_png(\n",
        "            draw_method=MermaidDrawMethod.API,\n",
        "        )\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "55a79c68-9210-421e-8548-618dec6318ad",
      "metadata": {
        "id": "55a79c68-9210-421e-8548-618dec6318ad",
        "outputId": "cd83b792-ab89-4e75-c3e5-fd193b5b82e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "APIConnectionError",
          "evalue": "Connection error.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mConnectError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_transports/default.py\u001b[0m in \u001b[0;36mmap_httpcore_exceptions\u001b[0;34m()\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0;32myield\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_transports/default.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmap_httpcore_exceptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/connection_pool.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    255\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_close_connections\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/connection_pool.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    235\u001b[0m                     \u001b[0;31m# Send the request on the assigned connection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m                     response = connection.handle_request(\n\u001b[0m\u001b[1;32m    237\u001b[0m                         \u001b[0mpool_request\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/connection.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_connect_failed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/connection.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     77\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_connection\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m                     \u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_connect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/connection.py\u001b[0m in \u001b[0;36m_connect\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    123\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"connect_tcp\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m                         \u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_network_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect_tcp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m                         \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_backends/sync.py\u001b[0m in \u001b[0;36mconnect_tcp\u001b[0;34m(self, host, port, timeout, local_address, socket_options)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mmap_exceptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m             sock = socket.create_connection(\n",
            "\u001b[0;32m/usr/lib/python3.11/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_exceptions.py\u001b[0m in \u001b[0;36mmap_exceptions\u001b[0;34m(map)\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_exc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mto_exc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;32mraise\u001b[0m  \u001b[0;31m# pragma: nocover\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mConnectError\u001b[0m: [Errno -2] Name or service not known",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mConnectError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m    995\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 996\u001b[0;31m             response = self._client.send(\n\u001b[0m\u001b[1;32m    997\u001b[0m                 \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 914\u001b[0;31m         response = self._send_handling_auth(\n\u001b[0m\u001b[1;32m    915\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36m_send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    941\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m                 response = self._send_handling_redirects(\n\u001b[0m\u001b[1;32m    943\u001b[0m                     \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36m_send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 979\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_single_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    980\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36m_send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrequest_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransport\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_transports/default.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    248\u001b[0m         )\n\u001b[0;32m--> 249\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mmap_httpcore_exceptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m             \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_transports/default.py\u001b[0m in \u001b[0;36mmap_httpcore_exceptions\u001b[0;34m()\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mmapped_exc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mConnectError\u001b[0m: [Errno -2] Name or service not known",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mAPIConnectionError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-246140b991ba>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Execute the workflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m response = await workflow.ainvoke(\n\u001b[0m\u001b[1;32m      3\u001b[0m         InputState(\n\u001b[1;32m      4\u001b[0m             \u001b[0mquery\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'My guess is a 5'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/__init__.py\u001b[0m in \u001b[0;36mainvoke\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, **kwargs)\u001b[0m\n\u001b[1;32m   2120\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2121\u001b[0m             \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2122\u001b[0;31m         async for chunk in self.astream(\n\u001b[0m\u001b[1;32m   2123\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2124\u001b[0m             \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/__init__.py\u001b[0m in \u001b[0;36mastream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[1;32m   2005\u001b[0m                 \u001b[0;31m# with channel updates applied only at the transition between steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2006\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtick\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_channels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2007\u001b[0;31m                     async for _ in runner.atick(\n\u001b[0m\u001b[1;32m   2008\u001b[0m                         \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m                         \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/runner.py\u001b[0m in \u001b[0;36matick\u001b[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[1;32m    442\u001b[0m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtasks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m                 await arun_with_retry(\n\u001b[0m\u001b[1;32m    445\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m                     \u001b[0mretry_policy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/retry.py\u001b[0m in \u001b[0;36marun_with_retry\u001b[0;34m(task, retry_policy, stream, configurable)\u001b[0m\n\u001b[1;32m    126\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mainvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mParentCommand\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0mns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCONF\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCONFIG_KEY_CHECKPOINT_NS\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/utils/runnable.py\u001b[0m in \u001b[0;36mainvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m                 )\n\u001b[1;32m    531\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mainvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mainvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/utils/runnable.py\u001b[0m in \u001b[0;36mainvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    318\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mASYNCIO_ACCEPTS_CONTEXT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m                 \u001b[0mcoro\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCoroutine\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m                 \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoro\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-c3ad6dd0159d>\u001b[0m in \u001b[0;36muser_guess\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m     54\u001b[0m     ]\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0mguess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mOutputState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_guess\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mguess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    282\u001b[0m         return cast(\n\u001b[1;32m    283\u001b[0m             \u001b[0mChatGeneration\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m             self.generate_prompt(\n\u001b[0m\u001b[1;32m    285\u001b[0m                 \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m                 \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    858\u001b[0m     ) -> LLMResult:\n\u001b[1;32m    859\u001b[0m         \u001b[0mprompt_messages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_messages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 860\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_messages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m     async def agenerate_prompt(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    688\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m                 results.append(\n\u001b[0;32m--> 690\u001b[0;31m                     self._generate_with_cache(\n\u001b[0m\u001b[1;32m    691\u001b[0m                         \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m                         \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36m_generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    923\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    924\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_manager\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 925\u001b[0;31m                 result = self._generate(\n\u001b[0m\u001b[1;32m    926\u001b[0m                     \u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_openai/chat_models/base.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    788\u001b[0m             \u001b[0mgeneration_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"headers\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 790\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mpayload\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    791\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_chat_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeneration_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m                         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Missing required argument: {quote(missing[0])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/resources/chat/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    857\u001b[0m     ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[1;32m    858\u001b[0m         \u001b[0mvalidate_response_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m    860\u001b[0m             \u001b[0;34m\"/chat/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m             body=maybe_transform(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1281\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1282\u001b[0m         )\n\u001b[0;32m-> 1283\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1285\u001b[0m     def patch(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    958\u001b[0m             \u001b[0mretries_taken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 960\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m    961\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mremaining_retries\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1020\u001b[0;31m                 return self._retry_request(\n\u001b[0m\u001b[1;32m   1021\u001b[0m                     \u001b[0minput_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m                     \u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_retry_request\u001b[0;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1096\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m   1099\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mremaining_retries\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1020\u001b[0;31m                 return self._retry_request(\n\u001b[0m\u001b[1;32m   1021\u001b[0m                     \u001b[0minput_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m                     \u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_retry_request\u001b[0;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1096\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m   1099\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1029\u001b[0m             \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Raising connection error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1030\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAPIConnectionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m         log.debug(\n",
            "\u001b[0;31mAPIConnectionError\u001b[0m: Connection error."
          ]
        }
      ],
      "source": [
        "# Execute the LangGraph workflow\n",
        "# Note - if you get a \"Connection Error\", that means your connection is probably blocked - you might\n",
        "# be outside your corporate firewall.\n",
        "\n",
        "response = await workflow.ainvoke(\n",
        "        InputState(\n",
        "            query='My guess is a 5',\n",
        "        )\n",
        "    )\n",
        "\n",
        "print(f'User Guessed - {response[\"user_guess\"]}')\n",
        "print(f'Dice Roll - {response[\"dice_roll\"]}')\n",
        "print(f'Final Response - {response[\"response\"]}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60562efc-1c2e-491a-8c91-68b6e9fcf51c",
      "metadata": {
        "id": "60562efc-1c2e-491a-8c91-68b6e9fcf51c"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}